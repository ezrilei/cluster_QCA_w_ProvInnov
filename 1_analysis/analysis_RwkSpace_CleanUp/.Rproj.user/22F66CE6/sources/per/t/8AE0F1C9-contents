# set up ----

## 设置工作目录 ----

# set the folder where the RScript locates as working dir (you need Rstudio to do this)
setwd(
  dirname(rstudioapi::getSourceEditorContext()$path)
)



# ## log start 《 ----
# library(logr)
# log_open("console.log")  # 开始日志记录

# format(Sys.time()

sink("【Anlysis_4】console_output.txt", split = TRUE)  # 开始记录


## load package ----

library(dplyr)
library(admisc)
library(QCA)



# library(ggrepel)
# library(ggplot2)
# library(stargazer)
# library(SetMethods)



## 设置  scientific penalty 选项以取消科学计数法表示 ----
options(scipen = 999)

## 打印更多内容， 10000个元素  ----
options(max.print = 10000)



## Importing Data ----
df.input <- readxl::read_excel(path = "./input/input4.xlsx",
                               sheet = 1
                               ) #%>% select(-c(X4)) # <------

## def outcome & conditions ---
outcome <- "Y"
#conditions <- c("X1", "X2", "X3", "X5", "X6")
conditions <- c( "X1", "X2", "X3", "X4", "X5", "X6", "X7", "X8", "X9") # <------------------


# 1. 校准 ----

## def e, c, i ←—— ----

# `罗光强,宋新宇.数字生态赋能农业新质生产力培育的制度组态——基于必要条件分析法与动态定性比较分析法[J].中国流通经济,2025,39(01):115-126.`
# > 参考格德斯（Guedes）等 `[31]`研究，
# 采用直接校 准法计算各变量的完全隶属、交叉点以及完全不隶属的3个校准点数值，
# 分别对应原始数据的`第95个百分位数`、`中位数`与`第5个百分位数`。
# > 
# >>`Guedes M J, da Conceição Gonçalves V, Soares N, et al. UK evidence for the determinants of R&D intensity from a panel fsQCA[J]. Journal of Business Research, 2016, 69(11): 5431-5436.`


exclu_qt <- 0.05
cross_qt <- 0.50
inclu_qt <- 0.95


# 因此本文参照权威文献方法（Fiss，2011），采用直接校准法。
# 根据变量在样本总体中的分布，
# 将样本的75%分位数、50%分位数和25%分位数分别设定为完全隶属、交叉点和完全不隶属的校准锚点，
# 该方法在学术界得到广泛运用（杜运周等，2020；贾建锋等，2023）。
# `方芳,张立杰,赵军.制度组态视角下提升农业绿色全要素生产率的多元路径探析——基于动态QCA的面板数据分析[J].中国农村经济,2024,(02):44-66.DOI:10.20077/j.cnki.11-1262/f.2024.02.003.`

# exclu_qt <- 0.25
# cross_qt <- 0.50
# inclu_qt <- 0.75

## calculate quantile for all variables (outcome and conditions) ----
quantiles <- df.input %>%
  select(-c(CASE, YEAR, ID)) %>%
  #select(Y, X1, X2, X3, X4, X5, X6) %>%
  lapply(
    function(column) {
      quantile(column,
               probs = c(exclu_qt, cross_qt, inclu_qt)
               )
      }
    )

## create string for Calibration functions setting ----
thresholds <- quantiles %>%
  lapply(
    function(qt) {
      paste0("e=", qt[1], ", c=", qt[2], ", i=", qt[3])
      }
    )

## visualization: Calibration anchor points Table ----
df.anchor <- data.frame(
  variable = c(outcome, conditions),
  inclusion = sapply(quantiles, function(qt) qt[3]),
  crossover = sapply(quantiles, function(qt) qt[2]),
  exclusion = sapply(quantiles, function(qt) qt[1])
)


# 移除rownames
rownames(df.anchor) <- NULL

# add column "type" to indicate "outcome" and  "condition"
# and move it to the first col
df.anchor <- df.anchor %>%
  mutate(type = if_else(variable == outcome, "outcome", "condition")) %>%
  select(type, everything())

### write df.anchor xlsx ----
writexl::write_xlsx(x = df.anchor,
                    path = "./output/【Anlysis_4】1.校准_df.anchor.xlsx"
                    )


## Calibration ★ ----

df.Fuzzy <- df.input

for (var in names(thresholds)) {
  df.Fuzzy[[var]] <- df.input[[var]] %>%
    QCA::calibrate(type = "fuzzy", 
                   thresholds = thresholds[[var]], 
                   logistic = TRUE)
}





## Crossover point ----

# fuzzy scores of 0.50 are replaced with 0.501 
# to prevent dropping significant configurations 
# from the subsequent analyses

# `盛亚, 冯媛媛, 施宇. 政府科研机构科技资源配置效率影响因素组态分析[J]. 科技进步与对策, 2022, 39(8): 1-9.`
# 
# > 由于在fsQCA分析中条件值为`0.5的会被自动删除`，
# > 因此本文`以0.501替换校准后为0.5的条件值`［２８］。
# >>`［２８］Ragin C C, Drass K A, Davey S. Fuzzy-set/qualitative comparative analysis 2.0[J]. Tucson, Arizona: Department of Sociology, University of Arizona, 2006, 23(6): 1949-1955.`

# 不能直接写等于，因为可能有float point error
# df.Fuzzy[df.Fuzzy == 0.50000000] <- 0.501
# df.Fuzzy[abs(df.Fuzzy - 0.5) < 1e-8] <- 0.501


for (var in names(thresholds)) {
  df.Fuzzy[[var]][abs(df.Fuzzy[[var]] - 0.5) < 1e-8] <- 0.501
}



# df.test <- df.Fuzzy %>%
#   filter(YEAR == 2021) %>%
#   filter(ID == "福建")
# 
# df.test$X6 == 0.50000000
# 0.5 - 0.50000000


### write df.Fuzzy xlsx ----
writexl::write_xlsx(x = df.Fuzzy,
                    path = "./output/【Anlysis_4】1.校准_df.Fuzzy.xlsx"
)


print("这是df.Fuzzy")
print(df.Fuzzy)


## CASE to rownames ----

# 后面Setmethod::cluster运算时，CASE要在rownames，
# 不然会报错：
# Error in SetMethods::cluster(data = data, results = result_label, outcome_var,  : 
# 'list' object cannot be coerced to type 'double'

df.Fuzzy <- as.data.frame(df.Fuzzy)
rownames(df.Fuzzy) <- df.Fuzzy$CASE
df.Fuzzy <- df.Fuzzy %>% select(-CASE)

# ——————----

# 2. def数据汇总函数 ----
analyze_data <- function(data, outcome_var, conditions, unit_id, cluster_id) {
  # cteate an empty data frame "results_summary"，
  # 用于存储汇总后的结果
  results_summary <- data.frame(
    outcome_var = character(), # <------
    Result_Type = character(),
    Inclusion_Type = character(),
    Pooled_Consistency = numeric(),
    Between_to_Pooled = numeric(),
    Pooled_Coverage = numeric(),
    stringsAsFactors = FALSE
  )
  
  for (condition in conditions) {
    for (inclusion_type in c("", "~")) {
      result_label <- paste(inclusion_type, condition, sep = "")
      output <- SetMethods::cluster(data = data, results = result_label, outcome_var, unit_id = unit_id, cluster_id = cluster_id, necessity = TRUE)
      
      # 打印每次 cluster 调用的结果
      print(paste("Results for", result_label))
      print(output)
      
      pooled_consistency <- output$POCOS
      between_to_pooled <- output$dBP
      pooled_coverage <- output$Coverages$pooled
      
      # 添加结果到数据框
      results_summary <- results_summary %>% 
        tibble::add_row(
          outcome_var = outcome_var, # <------
          Result_Type = result_label,
          Inclusion_Type = ifelse(inclusion_type == "~", "Excluded", "Included"),
          Pooled_Consistency = pooled_consistency,
          Between_to_Pooled = between_to_pooled,
          Pooled_Coverage = pooled_coverage
        )
    }
  }
  
  results_summary <- results_summary %>%
    # <------
    select(outcome_var, Result_Type, Pooled_Consistency, Pooled_Coverage, Between_to_Pooled) %>%
    mutate(across(where(is.numeric), ~round(., 3)))
  
  return(results_summary)
}

# ——————----


# 3. 必要条件分析 ----
## 3.1 高结果变量 ----
#### 3.1.1 组间 between ----
# conditions <- c("X1", "X2", "X3", "X4", "X5", "X6")
outcome_var <- "Y"
unit_id <- "ID"
cluster_id <- "YEAR"

print("这是results_summary_Y_between")
results_summary_Y_between <- analyze_data(df.Fuzzy, outcome_var, conditions, unit_id, cluster_id)

# Between_to_Pooled here is 
# the between consistency (BECONS) distance, 组间一致性距离
results_summary_Y_between <- results_summary_Y_between %>%
  rename(BECONS_distance = "Between_to_Pooled")

# print(results_summary_Y_between)


#### 3.1.2组内 within ----
# conditions <- c("X1", "X2", "X3", "X4", "X5", "X6")
outcome_var <- "Y"
unit_id <- "YEAR"
cluster_id <- "ID"

print("这是results_summary_Y_within")
results_summary_Y_within <- analyze_data(df.Fuzzy, outcome_var, conditions, unit_id, cluster_id)


# Between_to_Pooled here is 
# the within consistency (WICONS) distance, 组内一致性距离
results_summary_Y_within <- results_summary_Y_within %>%
  rename(WICONS_distance = "Between_to_Pooled")


#### 3.1.3 合并 组内&组间 结果 ----

# results_summary_Y_between 与 results_summary_Y_within，只有最后一列不一样
# 用前面4列 合并
results_summary_Y <- left_join(x = results_summary_Y_between, 
                               y = results_summary_Y_within, 
                               by = c("outcome_var", "Result_Type", "Pooled_Consistency", "Pooled_Coverage")
                               )

##### calculate adjusted distance ----

# `Castro R G, Ariño M A. A general approach to panel data set-theoretic research[J]. Journal of Advances in Management Sciences & Information Systems, 2016, 2: 63-76.`
# $$
# \text{BECONS adjusted distance} = \frac{\text{BECONS distance}}{\sqrt{\frac{n}{n^2 + 3n + 2}}}
# \text{WICONS adjusted distance} = \frac{\text{WICONS distance}}{\sqrt{\frac{n}{n^2 + 3n + 2}}}
# $$
#  n is equal to the number of elements in the vector
  
n.t.vec <- df.Fuzzy$YEAR %>% unique() %>% length()
n.N.vec <- df.Fuzzy$ID %>% unique() %>% length()


results_summary_Y <- results_summary_Y %>% 
  # calculate BECONS_adjusted_distance
  mutate(BECONS_adjusted_distance = BECONS_distance/sqrt(n.t.vec / (n.t.vec^2 + 3 * n.t.vec + 2))) %>%
  
  # caluculate WICONS_adjusted_distance
  mutate(WICONS_adjusted_distance = WICONS_distance/sqrt(n.N.vec / (n.N.vec^2 + 3 * n.N.vec + 2))) %>%
  
  # rm BECONS_distance、WICONS_distance
  select(-c(BECONS_distance, WICONS_distance))


print("这是results_summary_Y")
print(results_summary_Y)

##### write results_summary_Y xlsx ----

writexl::write_xlsx(x = results_summary_Y,
                    path = "./output/【Anlysis_4】3.必要性分析_results_summary_Y.xlsx"
                    )

## ——————----


## 3.2 低结果变量 ----
### 3.2.1 组间 between ----
# conditions <- c("X1", "X2", "X3", "X4", "X5", "X6")
outcome_var <- "~Y"
unit_id <- "ID"
cluster_id <- "YEAR"

print("这是results_summary_negY_between")
results_summary_negY_between <- analyze_data(df.Fuzzy, outcome_var, conditions, unit_id, cluster_id)

# Between_to_Pooled here is 
# the between consistency (BECONS) distance, 组间一致性距离
results_summary_negY_between <- results_summary_negY_between %>%
  rename(BECONS_distance = "Between_to_Pooled")



### 3.2.2 组内 within ----
# conditions <- c("X1", "X2", "X3", "X4", "X5", "X6")
outcome_var <- "~Y"
unit_id <- "YEAR"
cluster_id <- "ID"

print("这是results_summary_negY_within")
results_summary_negY_within <- analyze_data(df.Fuzzy, outcome_var, conditions, unit_id, cluster_id)

# Between_to_Pooled here is 
# the within consistency (WICONS) distance, 组内一致性距离
results_summary_negY_within <- results_summary_negY_within %>%
  rename(WICONS_distance = "Between_to_Pooled")


### 3.2.3 合并 组内&组间 结果 ----

# results_summary_negY_between 与 results_summary_negY_within，只有最后一列不一样
# 用前面4列 合并
results_summary_negY <- left_join(x = results_summary_negY_between, 
                               y = results_summary_negY_within, 
                               by = c("outcome_var", "Result_Type", "Pooled_Consistency", "Pooled_Coverage")
)

##### calculate adjusted distance ----

# n.t.vec <- df.Fuzzy$YEAR %>% unique() %>% length()
# n.N.vec <- df.Fuzzy$ID %>% unique() %>% length()

results_summary_negY <- results_summary_negY %>% 
  # calculate BECONS_adjusted_distance
  mutate(BECONS_adjusted_distance = BECONS_distance / sqrt(n.t.vec / (n.t.vec^2 + 3 * n.t.vec + 2))) %>%
  
  # caluculate WICONS_adjusted_distance
  mutate(WICONS_adjusted_distance = WICONS_distance / sqrt(n.N.vec / (n.N.vec^2 + 3 * n.N.vec + 2))) %>%
  
  # rm BECONS_distance、WICONS_distance
  select(-c(BECONS_distance, WICONS_distance))

print("这是results_summary_negY")
print(results_summary_negY)

##### write results_summary_negY xlsx ----

writexl::write_xlsx(x = results_summary_negY,
                    path = "./output/【Anlysis_4】3.必要性分析_results_summary_negY.xlsx"
)

# ——————----

# 4 充分性分析 ----
## 4.1 高结果变量 ----
### 4.1.1 构建真值表 ----

# `张明, 杜运周. 组织与管理研究中 QCA 方法的应用: 定位, 策略和方向[J]. 管理学报, 2019, 16(9): 1312.
# > 在`原始一致性阈值`方面，QCA方法专家提出了不同的可接受的`最低阈值`（如 `0.8`和`0.75`）

# `张明, 杜运周. 组织与管理研究中 QCA 方法的应用: 定位, 策略和方向[J]. 管理学报, 2019, 16(9): 1312.
# > 在实际操作过程中，一个普遍遵循的准则是：
# > `频数阈值的设定应当至少保留总案例数75％的比例`。


# `鲁若愚, 张立锴, 陈雪琳, 等. 基于科学的产业发展影响因素组态与路径研究——对中国内地 31 省份医药制造业的 QCA 分析[J]. 科技进步与对策, 2022, 39(16): 20-28.`
# > 为避免某一组态在结果和结果否定中的本文同时子集关系，
# > `PRI一致性门槛值不应低于0.5`，将PRI一致性阈值设定为 0.6。


tt_Y <- QCA::truthTable(data = df.Fuzzy, 
                        outcome = "Y", 
                        conditions = conditions, 
                        incl.cut = 0.75, n.cut = 2, pri.cut = 0.6, 
                        show.cases = TRUE,
                        sort.by = "OUT"
                        )

print("这是tt_Y")
tt_Y
#df.test <- tt_Y$tt

# 多大比例的案例能纳入后续分析
percent_case_1 <- (tt_Y$tt %>% filter(OUT == 1) %>% .$n %>% sum()) / (tt_Y$tt %>% .$n %>% sum())
print(paste0(percent_case_1*100, "%的案例，能纳入后续分析（在OUT=1的configuration中）"))


#### 寻找必要的组合，ron.cut代表必要相关性，参考标准为0.6 ----
# sp_Y <- QCA::superSubset(data = df.Fuzzy, 
#                          outcome = "Y", 
#                          conditions = conditions %>% paste(collapse = ","),  # "X1,X2,X3,X4,X5,X6"
#                          incl.cut = 0.90, ron.cut = 0.6
#                          )

sp_Y <- QCA::superSubset(data = df.Fuzzy,
                         outcome = "Y",
                         conditions = conditions %>% paste(collapse = ","),  # "X1,X2,X3,X4,X5,X6"
                         incl.cut = 0.90, ron.cut = 0.5
                         )



#### 寻找矛盾的逻辑余项 ----
row.untenable_LR <- findRows(obj = tt_Y, type = 2)  # contradictory simplifying assumptions

# > findRows(obj = tt_Y, type = 3) # 没有 simultaneous subset relations
# numeric(0)

# ————————————————————————————————————————————————————————————————————
# The following types of untenable assumptions can be searched for:
#   
# 0	all of them
# 1	subsets of a given expression (default)
# 2	contradictory simplifying assumptions <———
# 3	simultaneous subset relations


# The contradictory simplifying assumptions (CSAs) are those 
# which are used for both the presence and the absence of the outcome, 
# while simultaneous subset relations (SSRs) when observed configurations are sufficient for both the presence and the absence of the outcome.
# CSAs and SSRs are incoherent conterfactuals, part of a category called Untenable Assumptions.

# ————————————————————————————————————————————————————————————————————



#### 寻找一致性异常的案例 ----
# 一致性异常的案例 Deviant cases for consistency (DCC)
tt_Y_dcc <-  QCA::truthTable(data = df.Fuzzy,
                             outcome = "Y", 
                             conditions = conditions %>% paste(collapse = ","), 
                             incl.cut = 0.8, n.cut = 1, pri.cut = 0.6, 
                             show.cases = TRUE, 
                             # sort.by = "OUT", # 不能sort by OUT 因为后面slice是按行号进行的
                             complete = TRUE, 
                             dcc = TRUE)

print("这是tt_Y_dcc")
tt_Y_dcc

# get untenable_LR config from truthTable 
tt_Y_untenable_LR <- tt_Y_dcc$tt %>% 
  slice(row.untenable_LR) %>% 
  select(all_of(conditions)) # select(X1,X2,X3,......)




# def function
convert_to_expression <- function(row) {
  names <- colnames(tt_Y_untenable_LR)  # 获取列名
  terms <- ifelse(row == 1, names, paste0("~", names))  # 1: 直接列名, 0: 加上 ~
  paste(terms, collapse = "*")  # 用 "*" 连接所有变量
}

# end def function----


# 对数据框的每一行进行转换，并存入向量

# X1 X2 X3 X4 X5 X6 X7 X8 X9
# 116  0  0  1  1  1  0  0  1  1
# ↓
#                              116
# "~X1*~X2*X3*X4*X5*~X6*~X7*X8*X9"

untenable_LR_expressions <- apply(tt_Y_untenable_LR, 1, convert_to_expression)

#___________________________________________________ for a matrix 1 indicates rows



#### 清洗真值表 ----
tt_Y_clensed <- SetMethods::esa(oldtt = tt_Y, 
                                nec_cond = c(sp_Y$coms %>% colnames()), 
                                untenable_LR = c(untenable_LR_expressions)
                                )
print("这是tt_Y_clensed")
tt_Y_clensed


#### test ←——----

# tt_Y <- tt_Y_clensed

####  多大比例的案例进入了真值表 ----

# `张明, 杜运周. 组织与管理研究中 QCA 方法的应用: 定位, 策略和方向[J]. 管理学报, 2019, 16(9): 1312.
# 
# > 在实际操作过程中，一个普遍遵循的准则是：
# > `频数阈值的设定应当至少保留总案例数75％的比例`。



# 多大比例的案例能纳入后续分析
percent_case_2 <- (tt_Y_clensed$tt %>% filter(OUT == 1) %>% .$n %>% sum()) / (tt_Y_clensed$tt %>% .$n %>% sum())
print(paste0("经过Enhanced Standard Analysis，仅有", percent_case_2*100, "%的案例，能纳入后续分析（在OUT=1的configuration中）"))



# df.test <- tt_Y_clensed$tt

## test start —————————— ----

print("使用tt_Y（不经过Enhanced Standard Analysis）")

### 4.1.3 简单解 Parsimonious Solution ----
parsol_Y <- QCA::minimize(tt_Y, include = "?", details = TRUE)

print("这是parsol_Y")
parsol_Y

### 4.1.4 中间解 Intermediate Solution ----
# intsol_Y <- QCA::minimize(tt_Y, include = "?", dir.exp= "1,0,-,-,-,-", details = TRUE)
intsol_Y <- QCA::minimize(tt_Y, details = TRUE) # do not set any direction

print("这intsol_Y")
intsol_Y


## test end —————————— ----




### 4.1.2 复杂解 Complex Solution ----
print("使用tt_Y_clensed（经过Enhanced Standard Analysis）")


# compsol_Y <- QCA::minimize(tt_Y_clensed, details = TRUE)
# 
# print("这是compsol_Y，using tt_Y_clensed")
# compsol_Y

### 4.1.3 简单解 Parsimonious Solution ----
parsol_Y <- QCA::minimize(tt_Y_clensed, include = "?", details = TRUE)

print("这是parsol_Y，using tt_Y_clensed")
parsol_Y

### 4.1.4 中间解 Intermediate Solution ----
# intsol_Y <- QCA::minimize(tt_Y, include = "?", dir.exp= "1,0,-,-,-,-", details = TRUE)
intsol_Y <- QCA::minimize(tt_Y_clensed, details = TRUE) # do not set any direction

print("这是intsol_Y，using tt_Y_clensed")
intsol_Y

### 4.1.5 组间 using intsol_Y ----
cluster_data_Y_between <- SetMethods::cluster(data = df.Fuzzy, 
                                              results = intsol_Y, 
                                              outcome="Y", 
                                              unit_id = "ID", cluster_id = "YEAR", 
                                              sol = 1
                                              )
print("这是cluster_data_Y_between")
print(cluster_data_Y_between)

##### 提取  BECONS distance ----
# Between_to_Pooled here is 
# the between consistency (BECONS) distance, 组间一致性距离


# 获取所有逻辑表达式的名称
expr_names_between <- names(cluster_data_Y_between$output)

# 提取所有 dBP 值
dBP_values_between <- sapply(expr_names_between, function(expr) {
  cluster_data_Y_between$output[[expr]]$dBP
})

# 存入 DataFrame
df_dBP_between <- data.frame(Expression = expr_names_between, BECONS_distance = dBP_values_between)




### 4.1.6 组内 using intsol_Y ----
cluster_data_Y_within <- SetMethods::cluster(data = df.Fuzzy, 
                                             results = intsol_Y, 
                                             outcome="Y", 
                                             unit_id = "YEAR", cluster_id = "ID", 
                                             sol = 1
                                             )
print("这是cluster_data_Y_within")
print(cluster_data_Y_within)


##### 提取  WICONS distance ----
# Between_to_Pooled here is 
# the within consistency (WICONS) distance, 组内一致性距离

# 获取所有逻辑表达式的名称
expr_names_within <- names(cluster_data_Y_within$output)

# 提取所有 dBP 值
dBP_values_within <- sapply(expr_names_within, function(expr) {
  cluster_data_Y_within$output[[expr]]$dBP
})

# 存入 DataFrame
df_dBP_within <- data.frame(Expression = expr_names_within, WICONS_distance = dBP_values_within)


### 计算 adjusted distance ----

# 合并表格
df_dBP_Y <- df_dBP_between %>% left_join(df_dBP_within, by = "Expression")

# `Castro R G, Ariño M A. A general approach to panel data set-theoretic research[J]. Journal of Advances in Management Sciences & Information Systems, 2016, 2: 63-76.`
# $$
# \text{BECONS adjusted distance} = \frac{\text{BECONS distance}}{\sqrt{\frac{n}{n^2 + 3n + 2}}}
# \text{WICONS adjusted distance} = \frac{\text{WICONS distance}}{\sqrt{\frac{n}{n^2 + 3n + 2}}}
# $$
#  n is equal to the number of elements in the vector

# n.t.vec <- df.Fuzzy$YEAR %>% unique() %>% length()
# n.N.vec <- df.Fuzzy$ID %>% unique() %>% length()

df_dBP_Y <- df_dBP_Y %>% 
  # calculate BECONS_adjusted_distance
  mutate(BECONS_adjusted_distance = BECONS_distance/sqrt(n.t.vec / (n.t.vec^2 + 3 * n.t.vec + 2))) %>%
  
  # caluculate WICONS_adjusted_distance
  mutate(WICONS_adjusted_distance = WICONS_distance/sqrt(n.N.vec / (n.N.vec^2 + 3 * n.N.vec + 2))) %>%
  
  # rm BECONS_distance、WICONS_distance
  select(-c(BECONS_distance, WICONS_distance))


print("这是df_dBP_Y")
print(df_dBP_Y)

##### write results_summary_Y xlsx ----

writexl::write_xlsx(x = df_dBP_Y,
                    path = "./output/【Anlysis_4】4.充分性分析_组间、组内一致性调整距离_df_dBP_Y.xlsx"
)


## ——————----

## 4.2 低结果变量 ----

### 4.2.1 构建真值表 ----

tt_negY <- QCA::truthTable(data = df.Fuzzy, 
                        outcome = "~Y", 
                        conditions = conditions, 
                        incl.cut = 0.75, n.cut = 2, pri.cut = 0.5, 
                        show.cases = TRUE,
                        sort.by = "OUT"
)

print("这是tt_negY")
tt_negY


(tt_negY$tt %>% filter(OUT == 1) %>% .$n %>% sum()) / (tt_negY$tt %>% .$n %>% sum())


### 4.2.2 复杂解 Complex Solution ----
# compsol_negY <- QCA::minimize(tt_negY, details = TRUE)
# compsol_negY

### 4.2.3 简单解 Parsimonious Solution ----
parsol_negY <- QCA::minimize(tt_negY, include = "?", details = TRUE)

print("这是parsol_negY")
parsol_negY

### 4.2.4 中间解 Intermediate Solution ----
# intsol_negY <- QCA::minimize(tt_negY, include = "?", dir.exp= "1,0,-,-,-,-", details = TRUE)
intsol_negY <- QCA::minimize(tt_negY, details = TRUE) # do not set any direction

print("这是intsol_negY")
intsol_negY

### 4.2.5 组间 using intsol_negY ----
cluster_data_negY_between <- SetMethods::cluster(data = df.Fuzzy, 
                                                 results = intsol_negY, 
                                                 outcome="Y", 
                                                 unit_id = "ID", cluster_id = "YEAR", 
                                                 sol = 1
)
print(cluster_data_negY_between)

### 4.2.6 组内 using intsol_negY ----
cluster_data_negY_within <- SetMethods::cluster(data = df.Fuzzy, 
                                                results = intsol_negY, 
                                                outcome="Y", 
                                                unit_id = "YEAR", cluster_id = "ID", 
                                                sol = 1
)
print(cluster_data_negY_within)




# 5 稳健性检验
# 5.1 构建真值表

# 5.2 复杂解

# 5.3 简单解

# 5.4 中间解

# 5.5 组间

# 5.6 组内




## log end 《 ----
# log_close()  # 结束日志记录

sink()



